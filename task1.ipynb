{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1fe900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e573e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(title,image):\n",
    "    cv.imshow(title,image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea93da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    noise = cv.dilate(img, np.ones((7,7),np.uint8))\n",
    "    blur = cv.medianBlur(noise, 21)\n",
    "    res = 255 - cv.absdiff(img, blur)\n",
    "    no_shdw = cv.normalize(res,None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "    return no_shdw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9505439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    normalized = normalize(image)\n",
    "\n",
    "    image_m_blur = cv.medianBlur(normalized, 3)\n",
    "    # kernel_size = 3\n",
    "\n",
    "    image_g_blur = cv.GaussianBlur(image_m_blur, (0, 0), 7)\n",
    "    # kernel_size = (0, 0) (if it s 0, it s computed from sigma)\n",
    "    # std_deviation = 5\n",
    "\n",
    "    image_sharpened = cv.addWeighted(image_m_blur, 1.9, image_g_blur, -0.9, 0)\n",
    "    # last arg = scalar added to each sum\n",
    "\n",
    "    _, thresh = cv.threshold(image_sharpened, 180, 255, cv.THRESH_BINARY)\n",
    "    # threshold = 180\n",
    "    # maxValue = 255 (every pixel > threshold becomes maxValue and the rest become 0)\n",
    "\n",
    "    # Adaptive Gaussian Thresholding is worth trying (ofc, not exactly in this context) but made it work without it\n",
    "    # thresh = cv.adaptiveThreshold(image_sharpened, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    #                               cv.THRESH_BINARY, 11, 2)\n",
    "    # maxValue = 255, blockSize = 11 (size of a pixel neighborhood),\n",
    "    # C = 2 (constant substracted from the mean or weighted mean)\n",
    "\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "\n",
    "    eroded = cv.erode(thresh, kernel)\n",
    "\n",
    "    # I also applied the Sobel filter to get a look\n",
    "    sobelX = cv.Sobel(eroded, ddepth=cv.CV_32F, dx=1, dy=0)\n",
    "    sobelY = cv.Sobel(eroded, ddepth=cv.CV_32F, dx=0, dy=1)\n",
    "    sobelX = cv.convertScaleAbs(sobelX)\n",
    "    sobelY = cv.convertScaleAbs(sobelY)\n",
    "    # combine the gradient representations into a single image\n",
    "    sobel = cv.addWeighted(sobelX, 0.5, sobelY, 0.5, 0)\n",
    "    # just to take a look at the gradients\n",
    "    # print(labels)\n",
    "\n",
    "    edges = cv.Canny(eroded, 20, 150)\n",
    "    # threshold1 = 20 and threshold2 = 150 are used for the hysteresis procedure\n",
    "\n",
    "    # # Displaying each process result:\n",
    "    # show_image(\"original\", image)\n",
    "    # show_image(\"normalized\", normalized)\n",
    "    # show_image(\"median blurred\", image_m_blur)\n",
    "    # show_image(\"gaussian blurred\", image_g_blur)\n",
    "    # show_image(\"sharpened\", image_sharpened)\n",
    "    # show_image(\"threshold of blur\", thresh)\n",
    "    # show_image(\"eroded\", eroded)\n",
    "    # show_image(\"sobel\", sobel)\n",
    "    # show_image(\"canny\", edges)\n",
    "\n",
    "    contours, _ = cv.findContours(\n",
    "        edges,  cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    max_area = 0\n",
    "\n",
    "    for i in range(len(contours)):\n",
    "        if(len(contours[i]) > 3):\n",
    "            possible_top_left = None\n",
    "            possible_bottom_right = None\n",
    "            for point in contours[i].squeeze():\n",
    "                if possible_top_left is None or point[0] + point[1] < possible_top_left[0] + possible_top_left[1]:\n",
    "                    possible_top_left = point\n",
    "\n",
    "                if possible_bottom_right is None or point[0] + point[1] > possible_bottom_right[0] + possible_bottom_right[1]:\n",
    "                    possible_bottom_right = point\n",
    "\n",
    "            diff = np.diff(contours[i].squeeze(), axis=1)\n",
    "            possible_top_right = contours[i].squeeze()[np.argmin(diff)]\n",
    "            possible_bottom_left = contours[i].squeeze()[np.argmax(diff)]\n",
    "            if cv.contourArea(np.array([[possible_top_left], [possible_top_right], [possible_bottom_right], [possible_bottom_left]])) > max_area:\n",
    "                max_area = cv.contourArea(np.array([[possible_top_left], [possible_top_right], [\n",
    "                                          possible_bottom_right], [possible_bottom_left]]))\n",
    "                top_left = possible_top_left\n",
    "                bottom_right = possible_bottom_right\n",
    "                top_right = possible_top_right\n",
    "                bottom_left = possible_bottom_left\n",
    "\n",
    "    # # Displaying the 4 corners:\n",
    "    # image_copy = cv.cvtColor(image.copy(), cv.COLOR_GRAY2BGR)\n",
    "    # cv.circle(image_copy, tuple(top_left), 4, (0, 0, 255), -1)\n",
    "    # cv.circle(image_copy, tuple(top_right), 4, (0, 0, 255), -1)\n",
    "    # cv.circle(image_copy, tuple(bottom_left), 4, (0, 0, 255), -1)\n",
    "    # cv.circle(image_copy, tuple(bottom_right), 4, (0, 0, 255), -1)\n",
    "    # show_image(\"detected corners\", image_copy)\n",
    "\n",
    "    corners = np.asarray([top_left, top_right, bottom_left, bottom_right], dtype=\"float32\")\n",
    "    return corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38dd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sudoku(img):\n",
    "    corners = preprocess_image(img.copy())\n",
    "    top_left, top_right, bottom_left, bottom_right = corners\n",
    "\n",
    "    # calculating the length of each edge and picking the maximum\n",
    "    # width and height\n",
    "    width_bottom = np.sqrt(((bottom_right[0] - bottom_left[0])\n",
    "                            ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "    width_top = np.sqrt(((top_right[0] - top_left[0]) ** 2) +\n",
    "                        ((top_right[1] - top_left[1]) ** 2))\n",
    "    width = max(int(width_top), int(width_bottom))\n",
    "\n",
    "    height_right = np.sqrt(((top_right[0] - bottom_right[0]) ** 2) +\n",
    "                           ((top_right[1] - bottom_right[1]) ** 2))\n",
    "    height_left = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) +\n",
    "                          ((top_left[1] - bottom_left[1]) ** 2))\n",
    "    height = max(int(height_left), int(height_right))\n",
    "\n",
    "    dimensions = np.array([[0, 0], [width - 1, 0], [0, height - 1],\n",
    "                          [width - 1, height - 1]], dtype=\"float32\")\n",
    "\n",
    "    transform = cv.getPerspectiveTransform(corners, dimensions)\n",
    "    return cv.warpPerspective(img, transform, (width, height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119858ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we know that our final image is of size 500x500 (after resizing, of course),\n",
    "# and our sudoku consists of 9 rows and 9 columns, we can define the inside border lines\n",
    "# which will determine each cell\n",
    "lines_vertical = []\n",
    "lines_horizontal = []\n",
    "for i in range(0, 500, 55):\n",
    "    lines_vertical.append([(i, 0), (i, 499)])\n",
    "    lines_horizontal.append([(0, i), (499, i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e9452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cells(img, lines_horizontal, lines_vertical):\n",
    "    cells = []\n",
    "    padding = 10 # padding each cell with 5px to make sure we don't crop out the lines too\n",
    "    for i in range(len(lines_horizontal) - 1):\n",
    "        for j in range(len(lines_vertical) - 1):\n",
    "            y_min = lines_vertical[j][0][0] + padding\n",
    "            y_max = lines_vertical[j + 1][1][0] - padding\n",
    "            x_min = lines_horizontal[i][0][1] + padding\n",
    "            x_max = lines_horizontal[i + 1][1][1] - padding\n",
    "            cell = img[x_min:x_max, y_min:y_max].copy()\n",
    "            cells.append(cv.resize(cell, (28, 28)))  # resizing to 28x28 to match the cnn input size\n",
    "    return np.array(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f622727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(img):\n",
    "    model = tf.keras.models.load_model('saved_model/model.h5')\n",
    "    img = detect_sudoku(img)  # varying size, colored\n",
    "    img = cv.resize(img, (500, 500))  # fixed size\n",
    "    # show_image(\"sudoku\", img)  # show cropped image (sudoku rectangle)\n",
    "\n",
    "    # apply lines overlay:\n",
    "    for line in lines_vertical:\n",
    "        cv.line(img, line[0], line[1], (0, 255, 0), 5)\n",
    "    for line in lines_horizontal:\n",
    "        cv.line(img, line[0], line[1], (0, 0, 255), 5)\n",
    "    # show_image(\"img\", img)  # show sudoku with lines overlay\n",
    "\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  # fixed size, grayscale\n",
    "\n",
    "    cells = extract_cells(img, lines_horizontal, lines_vertical)  # each cell is a 28x28 grayscale image\n",
    "    cells = cells.reshape((cells.shape[0], 28, 28, 1)).astype('float32')\n",
    "    predictions = model.predict(cells)  # make predictions\n",
    "    labels = [np.argmax(prediction) for prediction in predictions]  # extract labels\n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a51b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(folder_path, samples):\n",
    "    for i in range(1, samples + 1):\n",
    "        if i < 10:\n",
    "            img = cv.imread(\n",
    "                f\"{folder_path}/0{i}.jpg\")\n",
    "        else:\n",
    "            img = cv.imread(\n",
    "                f\"{folder_path}/{i}.jpg\") \n",
    "        cell_labels = np.array(extract_information(img))\n",
    "        cell_labels = np.reshape(cell_labels, (9, 9))\n",
    "\n",
    "        file = open(f'results/clasic/{i}_predicted.txt', 'w')\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if cell_labels[j][k] == 0:\n",
    "                    char = 'o'\n",
    "                else:\n",
    "                    char = 'x'\n",
    "                file.write(char)\n",
    "            if j != 8:\n",
    "                file.write('\\n')\n",
    "        file.close()\n",
    "\n",
    "        file = open(f'results/clasic/{i}_bonus_predicted.txt', 'w')\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                char = str(cell_labels[j][k])\n",
    "                if char == '0':\n",
    "                    char = 'o'\n",
    "                file.write(char)\n",
    "            if j != 8:\n",
    "                file.write('\\n')\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52c90ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('/home/cosmin/Documents/Facultate/An3-Sem1/CAVA/Sudoku-Information-Extraction/datasets/antrenare/clasic', 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
